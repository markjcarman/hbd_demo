version: '3.1'

networks:
  hbd-demo-network:
    external: true
volumes:
  elasticsearch-data:
    driver: local

services:
  nginx:
    image: nginx
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    ports:
      - "51118:8080"
    networks:
      - hbd-demo-network
    depends_on:
      hbd_elasticsearch:
        condition: service_started
      hbd_frontend:
        condition: service_started
      hbd_backend:
        condition: service_started
      hbd_llamacpp:
        condition: service_started
      hbd_patient_search_backend:
        condition: service_started


  hbd_elasticsearch:
    image: elasticsearch:7.9.2
    container_name: hbd_elasticsearch
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data,
    environment:
      - discovery.type=single-node
      - cluster.routing.allocation.disk.threshold_enabled=false
    deploy:
      resources:
        limits:
          memory: 5G
    restart: "always"
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl --silent --fail localhost:9200/_cluster/health || exit 1"
        ]
      interval: 30s
      timeout: 30s
      retries: 3
    ports:
      - "51150:8000"
    networks:
      - hbd-demo-network

  hbd_llamacpp:
    container_name: hbd_llamacpp
    image: llama-cpp-python:latest
    build:
      context: ./llama-server/
      dockerfile: Dockerfile
    volumes:
      - ./models/:/models/
    command: sh -c "python3 -m llama_cpp.server --model /models/Meta-Llama-3-8B-Instruct-Q5_K_M.gguf --n_ctx 8182 --cache true --chat_format llama-3 --n_gpu_layers -1"
    environment:
      - HOST=0.0.0.0
    ports:
      - "51124:8000"
    deploy:
      resources:
        limits:
          memory: 32GB
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["1"]
              capabilities: [ gpu ]
    restart: "always"
    networks:
      - hbd-demo-network

  hbd_frontend:
    image: hbd-demo-frontend:latest
    build:
      context: ./frontend/
      dockerfile: Dockerfile
    volumes:
      - ./frontend/:/usr/src/app/
    # npm install
    container_name: hbd_frontend
    restart: "always"
    command: sh -c "npm install && npm audit fix --force && quasar dev"
    networks:
      - hbd-demo-network

  hbd_backend:
    build:
      context: ./backend/
      dockerfile: Dockerfile
    image: hbd-demo-backend:latest
    container_name: hbd_backend
    volumes:
      - ./backend/:/workspace/
      - ~/models/:/models/
    environment:
      - PYTHONUNBUFFERED=1
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: "always"
    deploy:
      resources:
        limits:
          memory: 20GB
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [ gpu ]
    networks:
      - hbd-demo-network

  hbd_patient_search_backend:
    build:
      context: ./patient-search-backend/
      dockerfile: Dockerfile
    image: patient-search-backend:latest
    container_name: hbd_patient_search_backend
    volumes:
      - ./patient-search-backend/:/workspace/
      - ./documents/:/documents/
    environment:
      - PYTHONUNBUFFERED=1
    restart: "always"
    networks:
      - hbd-demo-network


