version: '3.1'

networks:
  hbd-demo-network:
    external: true
volumes:
  elasticsearch-data:
    driver: local

services:
  nginx:
    image: nginx
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    ports:
      - "51118:8080"
    networks:
      - hbd-demo-network
    depends_on:
      elasticsearch:
        condition: service_started
      frontend:
        condition: service_started
      backend:
        condition: service_started
      llamacpp:
        condition: service_started

  elasticsearch:
    image: elasticsearch:7.9.2
    container_name: hbd-demo-elasticsearch_clinical
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data,
    environment:
      - discovery.type=single-node
    deploy:
      resources:
        limits:
          memory: 5G
    restart: "no"
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl --silent --fail localhost:9200/_cluster/health || exit 1"
        ]
      interval: 30s
      timeout: 30s
      retries: 3
    ports:
      - "51150:8000"
    networks:
      - hbd-demo-network

  llamacpp:
    container_name: llama-server
    image: llama-cpp-python:latest
    build:
      context: ./llama-server/
      dockerfile: Dockerfile
    volumes:
      - ~/models/:/models/
    command: sh -c "python3 -m llama_cpp.server --model /models/Meta-Llama-3-8B-Instruct.Q5_K_M.gguf --n_ctx 8182 --cache true --chat_format llama-3 --n_gpu_layers -1"
    environment:
      - HOST=0.0.0.0
    ports:
      - "51124:8000"
    deploy:
      resources:
        limits:
          memory: 32GB
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["1"]
              capabilities: [ gpu ]
    networks:
      - hbd-demo-network

  frontend:
    image: hbd-demo-frontend:latest
    build:
      context: ./frontend/
      dockerfile: Dockerfile
    volumes:
      - ./frontend/:/usr/src/app/
    # npm install
    container_name: hbd-demo-frontend
    restart: "no"
    command: sh -c "npm install && npm audit fix --force && quasar dev"
    networks:
      - hbd-demo-network
  backend:
    build:
      context: ./backend/
      dockerfile: Dockerfile
    image: hbd-demo-backend:latest
    container_name: hbd-demo-backend
    volumes:
      - ./backend/:/workspace/
      - ~/models/:/models/
    environment:
      - PYTHONUNBUFFERED=1
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: always
    deploy:
      resources:
        limits:
          memory: 20GB
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [ gpu ]
    networks:
      - hbd-demo-network
  patient-search-backend:
    build:
      context: ./patient-search-backend/
      dockerfile: Dockerfile
    image: patient-search-backend:latest
    container_name: patient-search-backend
    volumes:
      - ./patient-search-backend/:/workspace/
    environment:
      - PYTHONUNBUFFERED=1
    restart: always

    networks:
      - hbd-demo-network


